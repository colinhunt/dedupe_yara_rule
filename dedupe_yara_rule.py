#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
Author: marirs
Description: Look at files in a given path for yara rules, and dedupe them based on rule name
Version: 0.1
Requirements: python 2.7 & yara-python
Changelog: 0.1: initial commit
"""
from __future__ import print_function

import os
import io
import re
import sys
import argparse
import fnmatch
from datetime import datetime
from itertools import groupby

try:
    import yara
except:
    exit("[!] yara-python is not installed!")

sys.dont_write_bytecode = True

__version__ = 0.1
__author__ = "marirs@gmail.com"
__license__ = "GPL"
__file__ = "dedupe_yara_rule.py"


def chk_yara_import(Import):
    """
    Checks if the yara module exists or not!
    :param Import: yara import
    :return: returns true if exists else false
    """
    try:
        yara.compile(source=Import)
    except:
        return False

    return True

def write(filepath,contents):
    """
    Write contents to file
    :param filepath: filepath + filename
    :param content: contents that needs to be written (type: list or unicode string)
    :return: none
    """
    if type(contents) == list:
        contents = filter(None, map(lambda x: x.strip(), list(contents)))
        contents = "\n\n".join(contents)
    with io.open(filepath, 'w', encoding='utf-8') as f:
        try:
            print (unicode("/* file generated by yara deduper 0.1 */\n\n"), file=f)
            print (contents, file=f)
        except Exception, err:
            print ("[!] Error writing {}: {}".format(filepath,err))

def extract(yara_file):
    """
    Extracts rules, commented rules and imports from a given yara file
    :param yara_file: Yara file
    :return: tuple (list of imports/None, list yara rules/None, list of commented yara rules/None)
    """
    content = None
    yara_rules = []
    commented_yar_rules = []
    imports = []
    result_tuple = None
    yara_rule_regex = r"(^[\s+private]*rule\s[0-9a-zA-Z_\@\#\$\%\^\&\(\)\-\=\:\s]+\{.*?condition.*?\s\})"
    comments_regex = r"(/\*([^*]|[\r\n]|(\*+([^*/]|[\r\n])))*\*+/|^//.*?$)"
    imports_regex = r"(^import\s+.*?$)"

    with io.open(yara_file, "r", encoding="utf-8") as rule_file:
        # Read from rule file
        content = rule_file.read()

    if not content:
        return (None, None, None)

    rules_re = re.compile(yara_rule_regex, re.MULTILINE|re.DOTALL)
    yara_rules = rules_re.findall(content)
    # print ("File - {} [# of Rules - {}]".format(yara_file,len(match)))
    if yara_rules:
        # we have some yara rules in this file
        # lets check for comments or commented rules & the imports
        # in this rule file
        import_re = re.compile(imports_regex, re.MULTILINE|re.DOTALL)
        imports = import_re.findall(content)
        comments_re = re.compile(comments_regex, re.MULTILINE|re.DOTALL)
        commented_yar_rules = comments_re.findall(content)
        if commented_yar_rules:
            commented_yar_rules = [comments for sub in commented_yar_rules for comments in sub]
            commented_yar_rules = filter(None, commented_yar_rules)
            # lets find commented yara rules
            for yr in yara_rules:
                if yr in commented_yar_rules: #[0] if len(commented_yar_rules) > 0 else commented_yar_rules:
                    yara_rules.remove(yr)


    result_tuple = (imports, yara_rules, commented_yar_rules)
    return result_tuple

def dedupe(yara_rules_path, yara_output_path):
    """
    dedupe yara rules and store the unique ones in the output directory
    :param yara_rules_path: path to where yara rules are present
    :param yara_output_path: path to where deduped yara rules are written
    :return:
    """
    all_imports = set()
    all_yara_rules = set()
    rule_names = set()
    deduped_content = None
    total_duplicate_rules = 0
    total_rules = 0
    yara_rule_errors = {}
    yara_deduped_rules_path = os.path.join(yara_output_path,"deduped_rules")
    yara_commeted_rules_path = os.path.join(yara_output_path,"commented_rules")
    file_types = ["*.yar","*.yara"]
    yara_files = [os.path.join(root,f) for root, dir, files in os.walk(yara_rules_path) for f in fnmatch.filter(files, "*.yar") ]
    if not yara_files:
        exit("[!] 0 yara files to process from '{}'!".format(yara_rules_path))

    print ("[*] Total files to process: {} files in {} dirs.".format(
        len(yara_files),
        len(set([os.path.basename(os.path.normpath(os.path.dirname(f))) for f in yara_files])))
    )

    # go over all the yara rule files and process them
    for yf in yara_files:
        deduped_content = ""
        yara_src = ""
        yf_rule_dir = os.path.basename(os.path.normpath(os.path.dirname(yf)))
        new_yf_rule_dir = os.path.join(yara_deduped_rules_path,yf_rule_dir)
        new_yf_commented_rule_dir = os.path.join(yara_commeted_rules_path,yf_rule_dir)
        yf_file_name = os.path.basename(yf)

        imports, yar_rules, commented_yar_rules = extract(yf)
        if not imports and not yar_rules and not commented_yar_rules:
            print("[-] No yara rules found in {}".format(yf_file_name))
            continue

        if imports:
            # we found some imports
            all_imports.update(imports)
            deduped_content = "".join(imports)
            deduped_content += "\n\n\n"

        if commented_yar_rules:
            # commented rules found
            if not os.path.exists(new_yf_commented_rule_dir):
                os.mkdir(new_yf_commented_rule_dir)

            commented_yar_rules = imports+commented_yar_rules if imports else commented_yar_rules
            # write the commented rules to file
            write(os.path.join(new_yf_commented_rule_dir, yf_file_name), commented_yar_rules)

        if yar_rules:
            if not os.path.exists(new_yf_rule_dir):
                os.mkdir(new_yf_rule_dir)

            for r in yar_rules:
                rulename = r.splitlines()[0].strip().replace("{","").strip()
                if not rulename in rule_names:
                    deduped_content += "".join(r)
                    deduped_content += "\n\n"
                    rule_names.update(rulename)
                    all_yara_rules.add(r)
                else:
                    total_duplicate_rules += 1
                    print(" -> Duplicate rule: {}".format(rulename))

            # write the deduped rule to file
            write(os.path.join(new_yf_rule_dir, yf_file_name), deduped_content)

    total_rules = len(all_yara_rules)
    # Merge all the yara rules
    all_yara_rules = "\n".join(list(all_imports)) + "\n"*2 + "\n\n".join(list(all_yara_rules))
    # write all the deduped rules into 1 single file
    write(os.path.join(yara_deduped_rules_path,"all_in_one.yar"),all_yara_rules)
    print ("[*] Total # of Rules: {}\n[*] Total # of Duplicate Rules: {}".format(total_rules,total_duplicate_rules))

    # check if imports are available or not
    print ("-"*35)
    print ("[*] Checking import modules...")
    for module in all_imports:
        print (" -> {}: {}".format(module,"You dont have this module!" if not chk_yara_import(module) else "PASS"))

    print ("-"*35)
    # write index files
    print ("[*] Creating index files...")
    print (" -> {}".format(os.path.join(yara_deduped_rules_path,"all_in_one_rules.yar")))
    yara_files = [os.path.join(root, f) for root, dir, files in os.walk(yara_deduped_rules_path) for f in
                  fnmatch.filter(files, "*.yar") if "all_in_one_rules.yar" not in f]
    index_files = unicode("\n".join(["include \"{}\"".format(f) for f in yara_files]))
    write(os.path.join(yara_deduped_rules_path,"index.yar"),index_files)
    print (" -> {}".format(os.path.join(yara_deduped_rules_path,"index.yar")))
    # individual index files
    index_files = [(os.path.dirname(fp),os.path.basename(fp)) for fp in yara_files]
    for key, group in groupby(index_files, lambda x: x[0]):
        list_of_files = unicode("\n".join(["include \"{}/{}\"".format(file[0],file[1]) for file in group]))
        fname = os.path.basename(key)+"_index.yar"
        write(os.path.join(yara_deduped_rules_path,fname),list_of_files)
        print (" -> {}".format(os.path.join(yara_deduped_rules_path,fname)))
    print ("-"*35)
    # compile for rule errors
    print ("[*] Verifying rules...")

    for file in yara_files:
        try:
            # verify the rule file
            yara.compile(file)
        except Exception, err:
            print (" -> {} [skipped file due to compile error...]".format(err))

if __name__ == "__main__":
    """
    script begins :)
    """
    print ("Yara Rules deduper v{}".format(__version__))
    print ("marirs (at) gmail.com / Licence: GPL")
    print ("Disclaimer: This script is provided as-is without any warranty. Use at your own Risk :)")
    print ("Report bugs/issues at: https://github.com/marirs/dedupe_yara_rule/issues\n")

    parser = argparse.ArgumentParser(description='dedupe yara rules')
    parser.add_argument('-p', '--path', help='yara rules path', required=True)
    parser.add_argument('-o', '--out', default='./yara_new', help="output directory")
    args = parser.parse_args()

    if args.path:
        if not os.path.exists(args.path):
            exit ("[!] {} does not exist. a valid path to yara rules is required!".format(args.path))

    if args.out:
        misc_folders = ["commented_rules","deduped_rules"]
        if not os.path.exists(args.out):
            try:
                os.mkdir(args.out)
            except:
                exit ("[!] output directory does not exist and could not be created ({})".format(args.out))

        for f in misc_folders:
            if not os.path.exists(os.path.join(args.out,f)): os.mkdir(os.path.join(args.out,f))
        print ("[*] '{}' set to be the output directory!".format(os.path.join(os.getcwd(),str(args.out).replace("./","")) if "./" in args.out else args.out ))

    try:
        dedupe(args.path, args.out)
    except KeyboardInterrupt:
        exit ("\n[!] ^C pressed; stopping script!")

    print ("[*] All rules organised in {}".format(os.path.join(os.getcwd(),str(args.out).replace("./","")) if "./" in args.out else args.out ))
